{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ead55160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Temp.': {64: 'Yes',\n",
      "           65: 'No',\n",
      "           68: 'Yes',\n",
      "           69: 'Yes',\n",
      "           70: 'Yes',\n",
      "           71: 'No',\n",
      "           72: {'Outlook': {'Overcast': 'Yes', 'Sunny': 'No'}},\n",
      "           75: 'Yes',\n",
      "           80: 'No',\n",
      "           81: 'Yes',\n",
      "           83: 'Yes',\n",
      "           85: 'No'}}\n",
      "The decision for the new sample is: Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "import pprint\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Rain',\n",
    "                'Overcast', 'Sunny', 'Sunny', 'Rain', 'Sunny', \n",
    "                'Overcast', 'Overcast', 'Rain'],\n",
    "    'Temp.': [85, 80, 83, 70, 68, 65, 64, 72, 69, 75, 75, 72, 81, 71],\n",
    "    'Humidity': [85, 90, 78, 96, 80, 70, 65, 95, 70, 80, 70, 90, 75, 80],\n",
    "    'Wind': ['Weak', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong',\n",
    "             'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', \n",
    "             'Weak', 'Strong'],\n",
    "    'Decision': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes',\n",
    "                 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Function to calculate entropy\n",
    "def entropy(labels):\n",
    "    total = len(labels)\n",
    "    if total == 0:\n",
    "        return 0\n",
    "    label_counts = Counter(labels)\n",
    "    return -sum((count / total) * math.log2(count / total) for count in label_counts.values())\n",
    "\n",
    "# Function to calculate information gain\n",
    "def information_gain(df, attribute):\n",
    "    total_entropy = entropy(df['Decision'])\n",
    "    total = len(df)\n",
    "    \n",
    "    # Weighted entropy for splits\n",
    "    weighted_entropy = 0\n",
    "    for value in df[attribute].unique():\n",
    "        subset = df[df[attribute] == value]\n",
    "        weighted_entropy += (len(subset) / total) * entropy(subset['Decision'])\n",
    "    \n",
    "    return total_entropy - weighted_entropy\n",
    "\n",
    "# Function to build the decision tree\n",
    "def build_tree(df, attributes):\n",
    "    labels = df['Decision'].values\n",
    "    # Leaf node if all labels are the same\n",
    "    if len(set(labels)) == 1:\n",
    "        return labels[0]\n",
    "    \n",
    "    # Leaf node if no attributes are left\n",
    "    if not attributes:\n",
    "        return Counter(labels).most_common(1)[0][0]\n",
    "    \n",
    "    # Find the best attribute to split\n",
    "    best_attr = max(attributes, key=lambda attr: information_gain(df, attr))\n",
    "    tree = {best_attr: {}}\n",
    "    \n",
    "    for value in df[best_attr].unique():\n",
    "        subset = df[df[best_attr] == value]\n",
    "        if subset.empty:\n",
    "            tree[best_attr][value] = Counter(labels).most_common(1)[0][0]\n",
    "        else:\n",
    "            new_attributes = [attr for attr in attributes if attr != best_attr]\n",
    "            tree[best_attr][value] = build_tree(subset, new_attributes)\n",
    "    \n",
    "    return tree\n",
    "\n",
    "# Function to classify a new sample\n",
    "def classify(tree, sample):\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree  # Leaf node\n",
    "    attribute = next(iter(tree))\n",
    "    value = sample[attribute]\n",
    "    if value in tree[attribute]:\n",
    "        return classify(tree[attribute][value], sample)\n",
    "    else:\n",
    "        return None  # Unknown value\n",
    "\n",
    "# Build the decision tree\n",
    "attributes = ['Outlook', 'Temp.', 'Humidity', 'Wind']\n",
    "decision_tree = build_tree(df, attributes)\n",
    "\n",
    "# Print the tree\n",
    "import pprint\n",
    "pprint.pprint(decision_tree)\n",
    "\n",
    "# Classify a new sample\n",
    "new_sample = {'Outlook': 'Sunny', 'Temp.': 75, 'Humidity': 70, 'Wind': 'Weak'}\n",
    "decision = classify(decision_tree, new_sample)\n",
    "print(f\"The decision for the new sample is: {decision}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35f8ca34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Outlook': {'<= Overcast': 'Yes',\n",
      "             '> Overcast': {'Temp.': {'<= 75': 'Yes',\n",
      "                                      '> 75': {'Wind': {'<= Weak': {'Humidity': {'<= 85': 'No',\n",
      "                                                                                 '> 85': 'Yes'}},\n",
      "                                                        '> Weak': 'No'}}}}}}\n",
      "The decision for the new sample is: Yes\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate Gini Impurity\n",
    "def gini_impurity(data):\n",
    "    total = len(data)\n",
    "    if total == 0:\n",
    "        return 0\n",
    "    label_counts = Counter(data['Decision'])\n",
    "    return 1 - sum((count / total) ** 2 for count in label_counts.values())\n",
    "\n",
    "# Function to split dataset\n",
    "def split_dataset(df, attribute, value):\n",
    "    if isinstance(value, (int, float)):  # Numerical attribute\n",
    "        left_split = df[df[attribute] <= value]\n",
    "        right_split = df[df[attribute] > value]\n",
    "    else:  # Categorical attribute\n",
    "        left_split = df[df[attribute] == value]\n",
    "        right_split = df[df[attribute] != value]\n",
    "    \n",
    "    return left_split, right_split\n",
    "\n",
    "# Function to find the best split\n",
    "def best_split(df, attributes):\n",
    "    best_gini = float('inf')\n",
    "    best_attribute = None\n",
    "    best_value = None\n",
    "    \n",
    "    for attribute in attributes:\n",
    "        values = df[attribute].unique()\n",
    "        for value in values:\n",
    "            left_split, right_split = split_dataset(df, attribute, value)\n",
    "            gini_left = gini_impurity(left_split)\n",
    "            gini_right = gini_impurity(right_split)\n",
    "            gini = (len(left_split) / len(df)) * gini_left + (len(right_split) / len(df)) * gini_right\n",
    "            \n",
    "            if gini < best_gini:\n",
    "                best_gini = gini\n",
    "                best_attribute = attribute\n",
    "                best_value = value\n",
    "    \n",
    "    return best_attribute, best_value\n",
    "\n",
    "# Function to build the decision tree\n",
    "def build_tree(df, attributes):\n",
    "    labels = df['Decision'].values\n",
    "    \n",
    "    # Stop if all labels are the same\n",
    "    if len(set(labels)) == 1:\n",
    "        return labels[0]\n",
    "    \n",
    "    # Stop if no attributes are left to split\n",
    "    if not attributes:\n",
    "        return Counter(labels).most_common(1)[0][0]\n",
    "    \n",
    "    best_attribute, best_value = best_split(df, attributes)\n",
    "    tree = {best_attribute: {}}\n",
    "    \n",
    "    # Recursively build the tree\n",
    "    left_split, right_split = split_dataset(df, best_attribute, best_value)\n",
    "    \n",
    "    tree[best_attribute]['<= ' + str(best_value)] = build_tree(left_split, [attr for attr in attributes if attr != best_attribute])\n",
    "    tree[best_attribute]['> ' + str(best_value)] = build_tree(right_split, [attr for attr in attributes if attr != best_attribute])\n",
    "    \n",
    "    return tree\n",
    "\n",
    "# Function to classify a new sample\n",
    "def classify(tree, sample):\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree  # Leaf node\n",
    "    attribute = next(iter(tree))\n",
    "    value = sample[attribute]\n",
    "\n",
    "    for key in tree[attribute]:\n",
    "        if isinstance(value, str):  # Categorical attribute\n",
    "            if key.startswith('<=') and value == key[3:]:\n",
    "                return classify(tree[attribute][key], sample)\n",
    "            elif key.startswith('>') and value != key[2:]:\n",
    "                return classify(tree[attribute][key], sample)\n",
    "        else:  # Numerical attribute\n",
    "            threshold = float(key[3:]) if key.startswith('<=') else float(key[2:])\n",
    "            if (key.startswith('<=') and value <= threshold) or (key.startswith('>') and value > threshold):\n",
    "                return classify(tree[attribute][key], sample)\n",
    "    \n",
    "    return None \n",
    "\n",
    "# Build the decision tree\n",
    "attributes = ['Outlook', 'Temp.', 'Humidity', 'Wind']\n",
    "decision_tree = build_tree(df, attributes)\n",
    "\n",
    "# Print the tree\n",
    "pprint.pprint(decision_tree)\n",
    "\n",
    "# Classify a new sample\n",
    "new_sample = {'Outlook': 'Sunny', 'Temp.': 75, 'Humidity': 70, 'Wind': 'Weak'}\n",
    "decision = classify(decision_tree, new_sample)\n",
    "print(f\"The decision for the new sample is: {decision}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3330de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART Prediction for {'Income': {0: 'Medium'}, 'Credit': {0: 'Good'}}: Yes\n",
      "C4.5 Prediction for {'Income': {0: 'Medium'}, 'Credit': {0: 'Good'}}: Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample dataset\n",
    "data = {\n",
    "    'Income': ['Low', 'Low', 'Medium', 'Medium', 'High', 'High'],\n",
    "    'Credit': ['Good', 'Bad', 'Good', 'Bad', 'Good', 'Bad'],\n",
    "    'Loan Approved': ['Yes', 'No', 'Yes', 'Yes', 'Yes', 'No']\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Encode categorical variables (Income, Credit, Loan Approved) to numeric labels\n",
    "label_encoders = {}\n",
    "for column in df.columns:\n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = df[['Income', 'Credit']]\n",
    "y = df['Loan Approved']\n",
    "\n",
    "# Train CART Decision Tree (Gini index by default)\n",
    "cart_model = DecisionTreeClassifier(criterion='gini')\n",
    "cart_model.fit(X, y)\n",
    "\n",
    "# Train C4.5-like Decision Tree (using Entropy)\n",
    "c45_model = DecisionTreeClassifier(criterion='entropy')\n",
    "c45_model.fit(X, y)\n",
    "\n",
    "# Test the models with a new sample\n",
    "new_sample = pd.DataFrame({'Income': ['Medium'], 'Credit': ['Good']})\n",
    "\n",
    "# Encode the new sample\n",
    "new_sample_encoded = new_sample.copy()\n",
    "for column in new_sample.columns:\n",
    "    new_sample_encoded[column] = label_encoders[column].transform(new_sample[column])\n",
    "\n",
    "# Make predictions\n",
    "cart_prediction = cart_model.predict(new_sample_encoded)\n",
    "c45_prediction = c45_model.predict(new_sample_encoded)\n",
    "\n",
    "# Decode predictions back to Yes/No\n",
    "cart_prediction_decoded = label_encoders['Loan Approved'].inverse_transform(cart_prediction)\n",
    "c45_prediction_decoded = label_encoders['Loan Approved'].inverse_transform(c45_prediction)\n",
    "\n",
    "print(f\"CART Prediction for {new_sample.to_dict()}: {cart_prediction_decoded[0]}\")\n",
    "print(f\"C4.5 Prediction for {new_sample.to_dict()}: {c45_prediction_decoded[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0899ceee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
