{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c822a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884414e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9034d6ee",
   "metadata": {},
   "source": [
    "Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b19f043",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Text': [\n",
    "        \"A great game\",\n",
    "        \"The election was over\",\n",
    "        \"Very clean match\",\n",
    "        \"A clean but forgettable game\",\n",
    "        \"It was a close election\"\n",
    "    ],\n",
    "    'Tag': [\n",
    "        \"Sports\",\n",
    "        \"Not sports\",\n",
    "        \"Sports\",\n",
    "        \"Sports\",\n",
    "        \"Not sports\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "csv_file_path = 'word_dataset.csv'\n",
    "df.to_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e802618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Convert text to feature vectors\n",
    "X = vectorizer.fit_transform(df['Text'])\n",
    "\n",
    "# Target labels\n",
    "y = df['Tag'].apply(lambda x: 1 if x == 'Sports' else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a772781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def fit(self, X, y):\n",
    "        self.classes, class_counts = np.unique(y, return_counts=True)\n",
    "        self.class_prior = class_counts / len(y)\n",
    "        \n",
    "        self.feature_count = np.zeros((len(self.classes), X.shape[1]))\n",
    "        self.feature_total = np.zeros(len(self.classes))\n",
    "        \n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]\n",
    "            self.feature_count[c, :] = X_c.sum(axis=0)\n",
    "            self.feature_total[c] = X_c.shape[0]\n",
    "        \n",
    "        # Laplace smoothing\n",
    "        self.feature_prob = (self.feature_count + 1) / (self.feature_total[:, np.newaxis] + 2)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        log_prob = np.log(self.class_prior) + X @ np.log(self.feature_prob.T)\n",
    "        return self.classes[np.argmax(log_prob, axis=1)]\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        probas = []\n",
    "        for i in range(X.shape[0]):\n",
    "            row = X[i, :].toarray().flatten()\n",
    "            class_probs = {}\n",
    "            for cls in self.classes:\n",
    "                prior = np.log(self.class_prior[cls])\n",
    "                likelihood = 0\n",
    "                for feature_index in range(X.shape[1]):\n",
    "                    value = row[feature_index]\n",
    "                    prob = self.feature_probs[cls].get(feature_index, {}).get(value, 1 / (X.shape[0] + len(np.unique(row))))\n",
    "                    likelihood += np.log(prob)\n",
    "                class_probs[cls] = prior + likelihood\n",
    "            \n",
    "            total_prob = np.logaddexp.reduce(list(class_probs.values()))\n",
    "            prob_dist = {cls: np.exp(class_probs[cls] - total_prob) for cls in self.classes}\n",
    "            probas.append(prob_dist)\n",
    "        \n",
    "        return probas\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,stratify=y, random_state=42)\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "nb = NaiveBayesClassifier()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92167a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New sentence\n",
    "new_sentence = [\"A very close game\"]\n",
    "\n",
    "# Convert to feature vector\n",
    "X_new = vectorizer.transform(new_sentence)\n",
    "\n",
    "# Predict the class\n",
    "prediction = nb.predict(X_new)\n",
    "tag = 'Sports' if prediction[0] == 1 else 'Not sports'\n",
    "print(f\"The sentence '{new_sentence[0]}' is classified as: {tag}\")\n",
    "probabilities = nb.predict_proba(X_new)\n",
    "print(f\"Class probabilities for the sentence '{new_sentence[0]}': {probabilities[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e7de4b",
   "metadata": {},
   "source": [
    "Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3355500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_theorem(p_a_given_b, p_b, p_a):\n",
    "    return (p_a_given_b * p_b) / p_a\n",
    "\n",
    "def total_probability(p_a_given_b1, p_b1, p_a_given_b2, p_b2):\n",
    "    return p_a_given_b1 * p_b1 + p_a_given_b2 * p_b2\n",
    "\n",
    "# Problem (a)\n",
    "P_H = 0.60\n",
    "P_D = 0.40\n",
    "P_A_given_H = 0.30\n",
    "P_A_given_D = 0.20\n",
    "\n",
    "P_A = total_probability(P_A_given_H, P_H, P_A_given_D, P_D)\n",
    "P_H_given_A = bayes_theorem(P_A_given_H, P_H, P_A)\n",
    "print(f\"The probability that a student who scored an A grade is a hosteler is {P_H_given_A:.2f}\")\n",
    "\n",
    "# Problem (b)\n",
    "P_D = 0.01\n",
    "P_not_D = 0.99\n",
    "P_T_given_D = 0.99\n",
    "P_T_given_not_D = 0.02\n",
    "\n",
    "P_T = total_probability(P_T_given_D, P_D, P_T_given_not_D, P_not_D)\n",
    "P_D_given_T = bayes_theorem(P_T_given_D, P_D, P_T)\n",
    "print(f\"The probability of having the disease given a positive test result is {P_D_given_T:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491043bf",
   "metadata": {},
   "source": [
    "Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f504de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.class_prob = {}\n",
    "        self.feature_probs = defaultdict(lambda: defaultdict(lambda: defaultdict(float)))\n",
    "        self.features = []\n",
    "\n",
    "    def fit(self, df):\n",
    "        # Calculate prior probabilities for each class\n",
    "        total_records = len(df)\n",
    "        class_counts = df['buys_computer'].value_counts()\n",
    "        self.class_prob = {cls: count / total_records for cls, count in class_counts.items()}\n",
    "\n",
    "        # Calculate conditional probabilities for each feature given the class\n",
    "        self.features = df.columns[:-1]\n",
    "        for cls in self.class_prob:\n",
    "            class_df = df[df['buys_computer'] == cls]\n",
    "            feature_counts = {feature: class_df[feature].value_counts() for feature in self.features}\n",
    "            for feature in self.features:\n",
    "                total_feature_counts = class_df[feature].count()\n",
    "                for value, count in feature_counts[feature].items():\n",
    "                    self.feature_probs[feature][value][cls] = count / total_feature_counts\n",
    "\n",
    "    def predict(self, row):\n",
    "        probabilities = {}\n",
    "        for cls in self.class_prob:\n",
    "            prob = self.class_prob[cls]\n",
    "            for feature, value in row.items():\n",
    "                if value in self.feature_probs[feature]:\n",
    "                    prob *= self.feature_probs[feature][value].get(cls, 0)\n",
    "                else:\n",
    "                    prob = 0\n",
    "            probabilities[cls] = prob\n",
    "        \n",
    "        total_prob = sum(probabilities.values())\n",
    "        if total_prob == 0:\n",
    "            return None\n",
    "        probabilities = {cls: prob / total_prob for cls, prob in probabilities.items()}\n",
    "        return probabilities\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('q2.csv')\n",
    "\n",
    "# Initialize and train classifier\n",
    "nb_classifier = NaiveBayesClassifier()\n",
    "nb_classifier.fit(df)\n",
    "\n",
    "# Test row\n",
    "test_row = {\n",
    "    'Age': '31-40',\n",
    "    'Income': 'High',\n",
    "    'Student': 'Yes',\n",
    "    'Credit Rating': 'Fair'\n",
    "}\n",
    "\n",
    "# Predict probabilities for test row\n",
    "probabilities = nb_classifier.predict(test_row)\n",
    "print(f\"Probabilities for test row: {probabilities}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410f5262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "nb = NaiveBayesClassifier()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e46f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_index = 0 \n",
    "example_row = X_test.iloc[[example_index]]\n",
    "\n",
    "# Predict class\n",
    "predicted_class = nb.predict(example_row)\n",
    "print(f\"Predicted class for example row: {predicted_class[0]}\")\n",
    "\n",
    "# Predict probabilities\n",
    "predicted_proba = nb.predict_proba(example_row)\n",
    "print(f\"Class probabilities for example row: {predicted_proba[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
